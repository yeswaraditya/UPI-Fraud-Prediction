{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas numpy matplotlib seaborn joblib scikit-learn xgboost lightgbm catboost\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib as joblib\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# %pip install xgboost;\n",
    "# %pip install lightgbm;\n",
    "# %pip install catboost;\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/processed/upi_fraud_feature_engineered.csv\")\n",
    "X = data.drop(columns=['FraudFlag'])\n",
    "y = data['FraudFlag']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Model\n",
      "Accuracy: 0.7774, Precision: 0.6234, Recall: 0.0886, F1-score: 0.1551, ROC-AUC: 0.6986\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1778   29]\n",
      " [ 494   48]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.98      0.87      1807\n",
      "           1       0.62      0.09      0.16       542\n",
      "\n",
      "    accuracy                           0.78      2349\n",
      "   macro avg       0.70      0.54      0.51      2349\n",
      "weighted avg       0.75      0.78      0.71      2349\n",
      "\n",
      "\n",
      "Decision Tree Model\n",
      "Accuracy: 0.7944, Precision: 0.5492, Recall: 0.6070, F1-score: 0.5767, ROC-AUC: 0.7288\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1537  270]\n",
      " [ 213  329]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.86      1807\n",
      "           1       0.55      0.61      0.58       542\n",
      "\n",
      "    accuracy                           0.79      2349\n",
      "   macro avg       0.71      0.73      0.72      2349\n",
      "weighted avg       0.80      0.79      0.80      2349\n",
      "\n",
      "\n",
      "Random Forest Model\n",
      "Accuracy: 0.8740, Precision: 0.9805, Recall: 0.4631, F1-score: 0.6291, ROC-AUC: 0.8730\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1802    5]\n",
      " [ 291  251]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92      1807\n",
      "           1       0.98      0.46      0.63       542\n",
      "\n",
      "    accuracy                           0.87      2349\n",
      "   macro avg       0.92      0.73      0.78      2349\n",
      "weighted avg       0.89      0.87      0.86      2349\n",
      "\n",
      "\n",
      "Gradient Boosting Model\n",
      "Accuracy: 0.9017, Precision: 1.0000, Recall: 0.5738, F1-score: 0.7292, ROC-AUC: 0.8246\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1807    0]\n",
      " [ 231  311]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      1807\n",
      "           1       1.00      0.57      0.73       542\n",
      "\n",
      "    accuracy                           0.90      2349\n",
      "   macro avg       0.94      0.79      0.83      2349\n",
      "weighted avg       0.91      0.90      0.89      2349\n",
      "\n",
      "\n",
      "Support Vector Machine Model\n",
      "Accuracy: 0.8416, Precision: 0.8320, Recall: 0.3930, F1-score: 0.5338, ROC-AUC: 0.8185\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1764   43]\n",
      " [ 329  213]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.98      0.90      1807\n",
      "           1       0.83      0.39      0.53       542\n",
      "\n",
      "    accuracy                           0.84      2349\n",
      "   macro avg       0.84      0.68      0.72      2349\n",
      "weighted avg       0.84      0.84      0.82      2349\n",
      "\n",
      "\n",
      "K-Nearest Neighbors Model\n",
      "Accuracy: 0.7820, Precision: 0.5202, Recall: 0.7140, F1-score: 0.6019, ROC-AUC: 0.8292\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1450  357]\n",
      " [ 155  387]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.80      0.85      1807\n",
      "           1       0.52      0.71      0.60       542\n",
      "\n",
      "    accuracy                           0.78      2349\n",
      "   macro avg       0.71      0.76      0.73      2349\n",
      "weighted avg       0.81      0.78      0.79      2349\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pavan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\core.py:158: UserWarning: [21:04:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost Model\n",
      "Accuracy: 0.9132, Precision: 0.9801, Recall: 0.6365, F1-score: 0.7718, ROC-AUC: 0.8435\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1800    7]\n",
      " [ 197  345]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      1807\n",
      "           1       0.98      0.64      0.77       542\n",
      "\n",
      "    accuracy                           0.91      2349\n",
      "   macro avg       0.94      0.82      0.86      2349\n",
      "weighted avg       0.92      0.91      0.91      2349\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 2168, number of negative: 7227\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000463 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3601\n",
      "[LightGBM] [Info] Number of data points in the train set: 9395, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230761 -> initscore=-1.204019\n",
      "[LightGBM] [Info] Start training from score -1.204019\n",
      "\n",
      "LightGBM Model\n",
      "Accuracy: 0.9119, Precision: 0.9970, Recall: 0.6199, F1-score: 0.7645, ROC-AUC: 0.8277\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1806    1]\n",
      " [ 206  336]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      1807\n",
      "           1       1.00      0.62      0.76       542\n",
      "\n",
      "    accuracy                           0.91      2349\n",
      "   macro avg       0.95      0.81      0.86      2349\n",
      "weighted avg       0.92      0.91      0.90      2349\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pavan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\pavan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CatBoost Model\n",
      "Accuracy: 0.9166, Precision: 1.0000, Recall: 0.6384, F1-score: 0.7793, ROC-AUC: 0.8341\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1807    0]\n",
      " [ 196  346]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      1807\n",
      "           1       1.00      0.64      0.78       542\n",
      "\n",
      "    accuracy                           0.92      2349\n",
      "   macro avg       0.95      0.82      0.86      2349\n",
      "weighted avg       0.92      0.92      0.91      2349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"Support Vector Machine\": SVC(probability=True),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "    \"LightGBM\": LGBMClassifier(),\n",
    "    \"CatBoost\": CatBoostClassifier(verbose=0)\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipeline = Pipeline([(\"scaler\", StandardScaler()), (\"model\", model)])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_prob = pipeline.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_prob) if y_prob is not None else None\n",
    "\n",
    "    results.append([name, accuracy, precision, recall, f1, roc_auc])\n",
    "\n",
    "    joblib.dump(pipeline, f\"../models/{name.replace(' ', '_').lower()}.pkl\")\n",
    "\n",
    "    print(f\"\\n{name} Model\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}, ROC-AUC: {roc_auc:.4f}\")\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance Summary:\n",
      "                     Model  Accuracy  Precision    Recall  F1-score   ROC-AUC\n",
      "8                CatBoost  0.916560   1.000000  0.638376  0.779279  0.834115\n",
      "6                 XGBoost  0.913155   0.980114  0.636531  0.771812  0.843512\n",
      "7                LightGBM  0.911877   0.997033  0.619926  0.764505  0.827659\n",
      "3       Gradient Boosting  0.901660   1.000000  0.573801  0.729191  0.824564\n",
      "2           Random Forest  0.873989   0.980469  0.463100  0.629073  0.872977\n",
      "4  Support Vector Machine  0.841635   0.832031  0.392989  0.533835  0.818517\n",
      "1           Decision Tree  0.794381   0.549249  0.607011  0.576687  0.728796\n",
      "5     K-Nearest Neighbors  0.782035   0.520161  0.714022  0.601866  0.829211\n",
      "0     Logistic Regression  0.777352   0.623377  0.088561  0.155089  0.698616\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results, columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-score\", \"ROC-AUC\"])\n",
    "results_df.sort_values(by=\"Accuracy\", ascending=False, inplace=True)\n",
    "print(\"\\nModel Performance Summary:\\n\", results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Selected: CatBoost\n"
     ]
    }
   ],
   "source": [
    "best_model_name = results_df.iloc[0][\"Model\"]\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "print(f\"Best Model Selected: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/CatBoost.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(best_model, f\"../models/{best_model_name}.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
