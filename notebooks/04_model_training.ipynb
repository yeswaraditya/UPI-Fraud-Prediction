{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib as joblib\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# %pip install xgboost;\n",
    "# %pip install lightgbm;\n",
    "# %pip install catboost;\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/processed/upi_fraud_dataset_clean.csv\")\n",
    "X = data.drop(columns=['FraudFlag'])\n",
    "y = data['FraudFlag']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Model\n",
      "Accuracy: 0.7774, Precision: 0.6234, Recall: 0.0886, F1-score: 0.1551, ROC-AUC: 0.6986\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1778   29]\n",
      " [ 494   48]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.98      0.87      1807\n",
      "           1       0.62      0.09      0.16       542\n",
      "\n",
      "    accuracy                           0.78      2349\n",
      "   macro avg       0.70      0.54      0.51      2349\n",
      "weighted avg       0.75      0.78      0.71      2349\n",
      "\n",
      "\n",
      "Decision Tree Model\n",
      "Accuracy: 0.7935, Precision: 0.5476, Recall: 0.6052, F1-score: 0.5749, ROC-AUC: 0.7276\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1536  271]\n",
      " [ 214  328]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.86      1807\n",
      "           1       0.55      0.61      0.57       542\n",
      "\n",
      "    accuracy                           0.79      2349\n",
      "   macro avg       0.71      0.73      0.72      2349\n",
      "weighted avg       0.80      0.79      0.80      2349\n",
      "\n",
      "\n",
      "Random Forest Model\n",
      "Accuracy: 0.8736, Precision: 0.9842, Recall: 0.4594, F1-score: 0.6264, ROC-AUC: 0.8826\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1803    4]\n",
      " [ 293  249]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92      1807\n",
      "           1       0.98      0.46      0.63       542\n",
      "\n",
      "    accuracy                           0.87      2349\n",
      "   macro avg       0.92      0.73      0.78      2349\n",
      "weighted avg       0.89      0.87      0.86      2349\n",
      "\n",
      "\n",
      "Gradient Boosting Model\n",
      "Accuracy: 0.9017, Precision: 1.0000, Recall: 0.5738, F1-score: 0.7292, ROC-AUC: 0.8246\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1807    0]\n",
      " [ 231  311]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      1807\n",
      "           1       1.00      0.57      0.73       542\n",
      "\n",
      "    accuracy                           0.90      2349\n",
      "   macro avg       0.94      0.79      0.83      2349\n",
      "weighted avg       0.91      0.90      0.89      2349\n",
      "\n",
      "\n",
      "Support Vector Machine Model\n",
      "Accuracy: 0.8416, Precision: 0.8320, Recall: 0.3930, F1-score: 0.5338, ROC-AUC: 0.8186\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1764   43]\n",
      " [ 329  213]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.98      0.90      1807\n",
      "           1       0.83      0.39      0.53       542\n",
      "\n",
      "    accuracy                           0.84      2349\n",
      "   macro avg       0.84      0.68      0.72      2349\n",
      "weighted avg       0.84      0.84      0.82      2349\n",
      "\n",
      "\n",
      "K-Nearest Neighbors Model\n",
      "Accuracy: 0.7820, Precision: 0.5202, Recall: 0.7140, F1-score: 0.6019, ROC-AUC: 0.8292\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1450  357]\n",
      " [ 155  387]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.80      0.85      1807\n",
      "           1       0.52      0.71      0.60       542\n",
      "\n",
      "    accuracy                           0.78      2349\n",
      "   macro avg       0.71      0.76      0.73      2349\n",
      "weighted avg       0.81      0.78      0.79      2349\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pavan\\AppData\\Roaming\\Python\\Python311\\site-packages\\xgboost\\core.py:158: UserWarning: [23:28:17] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost Model\n",
      "Accuracy: 0.9115, Precision: 0.9771, Recall: 0.6310, F1-score: 0.7668, ROC-AUC: 0.8489\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1799    8]\n",
      " [ 200  342]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      1807\n",
      "           1       0.98      0.63      0.77       542\n",
      "\n",
      "    accuracy                           0.91      2349\n",
      "   macro avg       0.94      0.81      0.86      2349\n",
      "weighted avg       0.92      0.91      0.90      2349\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 2168, number of negative: 7227\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002106 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3601\n",
      "[LightGBM] [Info] Number of data points in the train set: 9395, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.230761 -> initscore=-1.204019\n",
      "[LightGBM] [Info] Start training from score -1.204019\n",
      "\n",
      "LightGBM Model\n",
      "Accuracy: 0.9119, Precision: 0.9970, Recall: 0.6199, F1-score: 0.7645, ROC-AUC: 0.8277\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1806    1]\n",
      " [ 206  336]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      1807\n",
      "           1       1.00      0.62      0.76       542\n",
      "\n",
      "    accuracy                           0.91      2349\n",
      "   macro avg       0.95      0.81      0.86      2349\n",
      "weighted avg       0.92      0.91      0.90      2349\n",
      "\n",
      "\n",
      "CatBoost Model\n",
      "Accuracy: 0.9153, Precision: 1.0000, Recall: 0.6328, F1-score: 0.7751, ROC-AUC: 0.8334\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1807    0]\n",
      " [ 199  343]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      1807\n",
      "           1       1.00      0.63      0.78       542\n",
      "\n",
      "    accuracy                           0.92      2349\n",
      "   macro avg       0.95      0.82      0.86      2349\n",
      "weighted avg       0.92      0.92      0.91      2349\n",
      "\n",
      "\n",
      "Model Performance Summary:\n",
      "                     Model  Accuracy  Precision    Recall  F1-score   ROC-AUC\n",
      "8                CatBoost  0.915283   1.000000  0.632841  0.775141  0.833445\n",
      "7                LightGBM  0.911877   0.997033  0.619926  0.764505  0.827659\n",
      "6                 XGBoost  0.911452   0.977143  0.630996  0.766816  0.848882\n",
      "3       Gradient Boosting  0.901660   1.000000  0.573801  0.729191  0.824563\n",
      "2           Random Forest  0.873563   0.984190  0.459410  0.626415  0.882608\n",
      "4  Support Vector Machine  0.841635   0.832031  0.392989  0.533835  0.818582\n",
      "1           Decision Tree  0.793529   0.547579  0.605166  0.574934  0.727597\n",
      "5     K-Nearest Neighbors  0.782035   0.520161  0.714022  0.601866  0.829211\n",
      "0     Logistic Regression  0.777352   0.623377  0.088561  0.155089  0.698613\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"Support Vector Machine\": SVC(probability=True),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "    \"LightGBM\": LGBMClassifier(),\n",
    "    \"CatBoost\": CatBoostClassifier(verbose=0)\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipeline = Pipeline([(\"scaler\", StandardScaler()), (\"model\", model)])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    y_prob = pipeline.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_prob) if y_prob is not None else None\n",
    "\n",
    "    results.append([name, accuracy, precision, recall, f1, roc_auc])\n",
    "\n",
    "    joblib.dump(pipeline, f\"../models/{name.replace(' ', '_').lower()}.pkl\")\n",
    "\n",
    "    print(f\"\\n{name} Model\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}, ROC-AUC: {roc_auc:.4f}\")\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance Summary:\n",
      "                     Model  Accuracy  Precision    Recall  F1-score   ROC-AUC\n",
      "8                CatBoost  0.915283   1.000000  0.632841  0.775141  0.833445\n",
      "7                LightGBM  0.911877   0.997033  0.619926  0.764505  0.827659\n",
      "6                 XGBoost  0.911452   0.977143  0.630996  0.766816  0.848882\n",
      "3       Gradient Boosting  0.901660   1.000000  0.573801  0.729191  0.824563\n",
      "2           Random Forest  0.873563   0.984190  0.459410  0.626415  0.882608\n",
      "4  Support Vector Machine  0.841635   0.832031  0.392989  0.533835  0.818582\n",
      "1           Decision Tree  0.793529   0.547579  0.605166  0.574934  0.727597\n",
      "5     K-Nearest Neighbors  0.782035   0.520161  0.714022  0.601866  0.829211\n",
      "0     Logistic Regression  0.777352   0.623377  0.088561  0.155089  0.698613\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results, columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-score\", \"ROC-AUC\"])\n",
    "results_df.sort_values(by=\"Accuracy\", ascending=False, inplace=True)\n",
    "print(\"\\nModel Performance Summary:\\n\", results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Selected: CatBoost\n"
     ]
    }
   ],
   "source": [
    "best_model_name = results_df.iloc[0][\"Model\"]\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "print(f\"Best Model Selected: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/CatBoost.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(best_model, f\"../models/{best_model_name}.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
