{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Raw Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (10000, 19)\n",
      "\n",
      "Missing Values:\n",
      " TransactionID           0\n",
      "UserID                  0\n",
      "Amount                  0\n",
      "Timestamp               0\n",
      "MerchantCategory        0\n",
      "TransactionType         0\n",
      "DeviceID                0\n",
      "IPAddress               0\n",
      "Latitude                0\n",
      "Longitude               0\n",
      "AvgTransactionAmount    0\n",
      "TransactionFrequency    0\n",
      "UnusualLocation         0\n",
      "UnusualAmount           0\n",
      "NewDevice               0\n",
      "FailedAttempts          0\n",
      "FraudFlag               0\n",
      "PhoneNumber             0\n",
      "BankName                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../data/raw/upi_fraud_dataset_raw.csv')\n",
    "\n",
    "print(\"Dataset Shape:\", data.shape)\n",
    "print(\"\\nMissing Values:\\n\", data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are No Missing Values in the DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Rows: 0\n",
      "New Shape After Removing Duplicates: (10000, 19)\n"
     ]
    }
   ],
   "source": [
    "print(\"Duplicate Rows:\", data.duplicated().sum())\n",
    "\n",
    "data = data.drop_duplicates()\n",
    "print(\"New Shape After Removing Duplicates:\", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransactionID             int64\n",
      "UserID                    int64\n",
      "Amount                  float64\n",
      "MerchantCategory          int64\n",
      "TransactionType           int64\n",
      "DeviceID                  int64\n",
      "IPAddress                 int32\n",
      "Latitude                float64\n",
      "Longitude               float64\n",
      "AvgTransactionAmount    float64\n",
      "TransactionFrequency      int32\n",
      "UnusualLocation            bool\n",
      "UnusualAmount              bool\n",
      "NewDevice                  bool\n",
      "FailedAttempts            int64\n",
      "FraudFlag                  bool\n",
      "PhoneNumber               int64\n",
      "BankName                  int32\n",
      "Hour                      int32\n",
      "Day                       int32\n",
      "Month                     int32\n",
      "Weekday                   int32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objects to Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "categorical_cols = ['UserID', 'MerchantCategory', 'TransactionType', 'DeviceID', 'IPAddress', 'BankName', 'TransactionFrequency']\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "    label_encoders[col] = le"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timestamp to DataTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Timestamp'] = pd.to_datetime(data['Timestamp'])\n",
    "\n",
    "data['Hour'] = data['Timestamp'].dt.hour\n",
    "data['Day'] = data['Timestamp'].dt.day\n",
    "data['Month'] = data['Timestamp'].dt.month\n",
    "data['Weekday'] = data['Timestamp'].dt.weekday\n",
    "\n",
    "data = data.drop(columns=['Timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean to Numerical Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_columns = ['UnusualLocation', 'UnusualAmount', 'NewDevice', 'FraudFlag']\n",
    "data[bool_columns] = data[bool_columns].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransactionID             int64\n",
      "UserID                    int64\n",
      "Amount                  float64\n",
      "MerchantCategory          int64\n",
      "TransactionType           int64\n",
      "DeviceID                  int64\n",
      "IPAddress                 int32\n",
      "Latitude                float64\n",
      "Longitude               float64\n",
      "AvgTransactionAmount    float64\n",
      "TransactionFrequency      int32\n",
      "UnusualLocation           int32\n",
      "UnusualAmount             int32\n",
      "NewDevice                 int32\n",
      "FailedAttempts            int64\n",
      "FraudFlag                 int32\n",
      "PhoneNumber               int64\n",
      "BankName                  int32\n",
      "Hour                      int32\n",
      "Day                       int32\n",
      "Month                     int32\n",
      "Weekday                   int32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = data['Amount'].quantile(0.25)\n",
    "Q3 = data['Amount'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "data = data[(data['Amount'] >= lower_bound) & (data['Amount'] <= upper_bound)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "data_standardized = data.copy()\n",
    "data_minmax = data.copy()\n",
    "scaler_std = StandardScaler()\n",
    "num_cols = ['Amount', 'Latitude', 'Longitude', 'AvgTransactionAmount', 'FailedAttempts', 'Hour', 'Day', 'Month', 'Weekday']\n",
    "data_standardized[num_cols] = scaler_std.fit_transform(data_standardized[num_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For MinMax Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_minmax = MinMaxScaler()\n",
    "data_minmax[num_cols] = scaler_minmax.fit_transform(data_minmax[num_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Class Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution:\n",
      " FraudFlag\n",
      "0    0.769244\n",
      "1    0.230756\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Class Distribution:\\n\", data['FraudFlag'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X = data.drop(columns=['FraudFlag'])\n",
    "y = data['FraudFlag']\n",
    "\n",
    "smote = SMOTE(sampling_strategy=0.3, random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "data = pd.DataFrame(X_resampled, columns=X.columns)\n",
    "data['FraudFlag'] = y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Class Distribution:\n",
      " FraudFlag\n",
      "0    0.769244\n",
      "1    0.230756\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"New Class Distribution:\\n\", data['FraudFlag'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardized Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(sampling_strategy=0.3, random_state=42)\n",
    "\n",
    "X_std = data_standardized.drop(columns=['FraudFlag'])\n",
    "y_std = data_standardized['FraudFlag']\n",
    "X_resampled_std, y_resampled_std = smote.fit_resample(X_std, y_std)\n",
    "\n",
    "data_standardized = pd.DataFrame(X_resampled_std, columns=X_std.columns)\n",
    "data_standardized['FraudFlag'] = y_resampled_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinMax Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_minmax = data_minmax.drop(columns=['FraudFlag'])\n",
    "y_minmax = data_minmax['FraudFlag']\n",
    "X_resampled_minmax, y_resampled_minmax = smote.fit_resample(X_minmax, y_minmax)\n",
    "data_minmax = pd.DataFrame(X_resampled_minmax, columns=X_minmax.columns)\n",
    "data_minmax['FraudFlag'] = y_resampled_minmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed datasets saved successfully!\n"
     ]
    }
   ],
   "source": [
    "data.to_csv('../data/processed/upi_fraud_dataset_clean.csv', index=False)\n",
    "data_standardized.to_csv('../data/processed/upi_fraud_dataset_standardized.csv', index=False)\n",
    "data_minmax.to_csv('../data/processed/upi_fraud_dataset_minmax.csv', index=False)\n",
    "\n",
    "print(\"Processed datasets saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
